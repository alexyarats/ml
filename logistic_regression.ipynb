{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/alexyarats/ml/blob/master/logistic_regression.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "rKnlTcekCP7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFbLl8IAeffM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Prepare data**"
      ]
    },
    {
      "metadata": {
        "id": "aT05gw2uCUEO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "breast_cancer = datasets.load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "61ixI3pWCavQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, x_valid = breast_cancer.data[:450], breast_cancer.data[450:]\n",
        "y_train, y_valid = breast_cancer.target[:450], breast_cancer.target[450:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3zCDB1SekUV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "metadata": {
        "id": "W14Cx2-ZQEWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Param(object):\n",
        "  def __init__(self, shape):\n",
        "    self.data = np.zeros(shape)\n",
        "    self.grad = np.zeros(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oe1QFZa6FRdq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NumpyLogisticRegression(object):\n",
        "  def __init__(self):\n",
        "    self.W = Param(30)\n",
        "    self.b = Param(1)\n",
        "    \n",
        "  def parameters(self):\n",
        "    return [self.W, self.b]\n",
        "  \n",
        "  def forward(self, X):\n",
        "    h = X.dot(self.W.data) + self.b.data\n",
        "    return 1./(1. + np.exp(-h))\n",
        "  \n",
        "  def backward(self, X, y, y_hat):\n",
        "    self.W.grad = -np.average(X * (y - y_hat).reshape(y.shape[0], 1), axis=0)\n",
        "    self.b.grad = -np.average(y - y_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_J4Ca-kRPjbb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SGD(object):\n",
        "  def __init__(self, params, lr=0.00001):\n",
        "    self.params = params\n",
        "    self.lr = lr\n",
        "  \n",
        "  def zero_grad(self):\n",
        "    for p in self.params:\n",
        "      p.grad.fill(0.)\n",
        "    \n",
        "  def step(self):\n",
        "    for p in self.params:\n",
        "      p.data -= self.lr * p.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDX44LTJerWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loss and predict**"
      ]
    },
    {
      "metadata": {
        "id": "oMcVwA3XQ-D4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eps=1e-6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E_jBr4ClMEee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss(y, y_hat):\n",
        "  return -np.average(y * np.log(y_hat.clip(eps, 1 - eps)) +\n",
        "                     (1 - y) * np.log(1 - y_hat.clip(eps, 1 - eps)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZkd-gV6Lt7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(model, X):\n",
        "  return np.array(model.forward(X)) > 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AI2f-zGfev8z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model with batches**"
      ]
    },
    {
      "metadata": {
        "id": "mJgcv2SSSdIM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "b33ba808-c86d-4cff-9f1b-7ecfa204b993"
      },
      "cell_type": "code",
      "source": [
        "m = NumpyLogisticRegression()\n",
        "optim = SGD(m.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "loss_valid = None\n",
        "\n",
        "#idx = np.arange(len(x_train))\n",
        "\n",
        "print(\"Learning rate: %.8f\" % optim.lr)\n",
        "\n",
        "for epoch in range(200):\n",
        "  \n",
        "  idx = np.arange(len(x_train))\n",
        "  np.random.shuffle(idx)\n",
        "  batch = idx[0: batch_size]\n",
        "    \n",
        "  optim.zero_grad()\n",
        "  y_hat = m.forward(x_train[batch])\n",
        "  m.backward(x_train[batch], y_train[batch], y_hat)\n",
        "  optim.step()\n",
        "  \n",
        "  loss_v = loss(y_valid, m.forward(x_valid))\n",
        "  \n",
        "  if epoch % 5 == 0:\n",
        "    loss_v = loss(y_valid, m.forward(x_valid))\n",
        "    #print(\"Loss: %.5f\" % loss_v)\n",
        "    if loss_valid is None or loss_v > loss_valid:\n",
        "      optim.lr /= 2\n",
        "      print(\"Learning rate: %.8f\" % optim.lr)\n",
        "    loss_valid = loss_v\n",
        "    \n",
        "  if optim.lr < 1e-8:\n",
        "    break\n",
        "    \n",
        "  y_pred = predict(m, x_valid)\n",
        "  #print(\"Epoch: %d, accuracy = %.8f\" % (epoch + 1, accuracy_score(y_valid, y_pred)))\n",
        "\n",
        "print(\"Loss: %.5f\" % loss_v)  \n",
        "  \n",
        "print(\"-------------------------\")\n",
        "forward = m.forward(x_valid)\n",
        "y_pred = np.array(forward) > 0.5\n",
        "\n",
        "print(\"Accuracy: %.5f\" % accuracy_score(y_valid, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 0.00100000\n",
            "Learning rate: 0.0005000\n",
            "Learning rate: 0.0002500\n",
            "Learning rate: 0.0001250\n",
            "Learning rate: 0.0000625\n",
            "Learning rate: 0.0000313\n",
            "Learning rate: 0.0000156\n",
            "Learning rate: 0.0000078\n",
            "Learning rate: 0.0000039\n",
            "Learning rate: 0.0000020\n",
            "Learning rate: 0.0000010\n",
            "Learning rate: 0.0000005\n",
            "Learning rate: 0.0000002\n",
            "Learning rate: 0.0000001\n",
            "Learning rate: 0.0000001\n",
            "Learning rate: 0.0000000\n",
            "Learning rate: 0.0000000\n",
            "Learning rate: 0.0000000\n",
            "Loss: 1.38447\n",
            "-------------------------\n",
            "Accuracy: 0.79832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5WOLFy20e7U-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model withoit batches**"
      ]
    },
    {
      "metadata": {
        "id": "OqfP2LkQe0TA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "eb4a4ca6-4ea4-4db5-f805-a7e665ce942d"
      },
      "cell_type": "code",
      "source": [
        "m = NumpyLogisticRegression()\n",
        "optim = SGD(m.parameters(), lr=0.00001)\n",
        "\n",
        "loss_valid = None\n",
        "\n",
        "print(\"Learning rate: %.8f\" % optim.lr)\n",
        "\n",
        "for epoch in range(50):\n",
        "    \n",
        "  optim.zero_grad()\n",
        "  y_hat = m.forward(x_train)\n",
        "  m.backward(x_train, y_train, y_hat)\n",
        "  optim.step()\n",
        "  \n",
        "  loss_v = loss(y_valid, m.forward(x_valid))\n",
        "  \n",
        "  if epoch % 5 == 0:\n",
        "    loss_v = loss(y_valid, m.forward(x_valid))\n",
        "    #print(\"Loss: %.5f\" % loss_v)\n",
        "    if loss_valid is None or loss_v > loss_valid:\n",
        "      optim.lr /= 2\n",
        "      print(\"Learning rate: %.8f\" % optim.lr)\n",
        "    loss_valid = loss_v\n",
        "    \n",
        "  if optim.lr < 1e-8:\n",
        "    break\n",
        "    \n",
        "  y_pred = predict(m, x_valid)\n",
        "  #print(\"Epoch: %d, accuracy = %.8f\" % (epoch + 1, accuracy_score(y_valid, y_pred)))\n",
        "\n",
        "print(\"Loss: %.5f\" % loss_v)  \n",
        "  \n",
        "print(\"-------------------------\")\n",
        "forward = m.forward(x_valid)\n",
        "y_pred = np.array(forward) > 0.5\n",
        "\n",
        "print(\"Accuracy: %.5f\" % accuracy_score(y_valid, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 0.00001000\n",
            "Learning rate: 0.00000500\n",
            "Learning rate: 0.00000250\n",
            "Loss: 0.65052\n",
            "-------------------------\n",
            "Accuracy: 0.50420\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}